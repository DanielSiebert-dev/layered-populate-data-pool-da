{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# /scripts/extract_kindergartens_osm.py\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def get_osm_data(bbox):\n",
        "    \"\"\"\n",
        "    Queries the Overpass API for all kindergartens within a given bounding box.\n",
        "\n",
        "    Args:\n",
        "        bbox (str): A string representing the bounding box in the format \"south,west,north,east\".\n",
        "                    Example for Berlin: \"52.3,13.0,52.6,13.8\"\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the extracted data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Overpass API endpoint\n",
        "        overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
        "\n",
        "        # Overpass QL query to find all nodes, ways, and relations with 'amenity=kindergarten'\n",
        "        # within the specified bounding box.\n",
        "        overpass_query = f\"\"\"\n",
        "            [out:json][timeout:25];\n",
        "            (\n",
        "              node[\"amenity\"=\"kindergarten\"]({bbox});\n",
        "              way[\"amenity\"=\"kindergarten\"]({bbox});\n",
        "              relation[\"amenity\"=\"kindergarten\"]({bbox});\n",
        "            );\n",
        "            out body;\n",
        "            >;\n",
        "            out skel qt;\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Requesting data from Overpass API...\")\n",
        "        response = requests.get(overpass_url, data={'data': overpass_query})\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the JSON response\n",
        "        data = response.json()\n",
        "        elements = data.get('elements', [])\n",
        "\n",
        "        kindergartens = []\n",
        "        for element in elements:\n",
        "            if element['type'] in ['node', 'way', 'relation']:\n",
        "                tags = element.get('tags', {})\n",
        "                kindergarten = {\n",
        "                    'id': element['id'],\n",
        "                    'latitude': element.get('lat', tags.get('lat')), # Coordinates for nodes are direct\n",
        "                    'longitude': element.get('lon', tags.get('lon')),\n",
        "                    'name': tags.get('name'),\n",
        "                    'address': tags.get('addr:full'),\n",
        "                    'street': tags.get('addr:street'),\n",
        "                    'housenumber': tags.get('addr:housenumber'),\n",
        "                    'postcode': tags.get('addr:postcode'),\n",
        "                    'city': tags.get('addr:city'),\n",
        "                }\n",
        "                kindergartens.append(kindergarten)\n",
        "\n",
        "        df = pd.DataFrame(kindergartens)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error interacting with the Overpass API: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to orchestrate the data extraction process.\n",
        "    \"\"\"\n",
        "    # Bounding box for Berlin, Germany (south, west, north, east)\n",
        "    berlin_bbox = \"52.34,13.1,52.6,13.8\"\n",
        "\n",
        "    kindergarten_df = get_osm_data(berlin_bbox)\n",
        "\n",
        "    if not kindergarten_df.empty:\n",
        "        # Save the DataFrame to a CSV file in the 'sources' directory\n",
        "        raw_data_path = '../sources/kindergartens_berlin_raw_osm.csv'\n",
        "        os.makedirs(os.path.dirname(raw_data_path), exist_ok=True)\n",
        "        kindergarten_df.to_csv(raw_data_path, index=False)\n",
        "        print(f\"Data successfully extracted and saved to: {raw_data_path}\")\n",
        "    else:\n",
        "        print(\"No data was extracted.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kd9PtJmfvVu",
        "outputId": "d738a3d2-834b-4f1a-a91b-3ea26a3a0fd5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requesting data from Overpass API...\n",
            "Data successfully extracted and saved to: ../sources/kindergartens_berlin_raw_osm.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /scripts/transform_kindergartens.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def clean_data(raw_data_path, cleaned_data_path):\n",
        "    \"\"\"\n",
        "    Cleans and normalizes the raw kindergarten data from OSM.\n",
        "\n",
        "    Args:\n",
        "        raw_data_path (str): The path to the raw data CSV file.\n",
        "        cleaned_data_path (str): The path to save the cleaned data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load the raw data from the CSV file\n",
        "        df = pd.read_csv(raw_data_path)\n",
        "        print(\"Raw data loaded successfully.\")\n",
        "\n",
        "        # --- Data Cleaning and Transformation ---\n",
        "\n",
        "        # 1. Combine street and housenumber into a single 'address' column\n",
        "        df['street'] = df['street'].fillna('')\n",
        "        df['housenumber'] = df['housenumber'].fillna('')\n",
        "        df['address'] = df['street'].astype(str) + ' ' + df['housenumber'].astype(str)\n",
        "        df['address'] = df['address'].str.strip()\n",
        "        df.loc[df['address'] == '', 'address'] = df['city'].fillna('Unknown')\n",
        "\n",
        "        # 2. Add 'operator' column if it doesn't exist, as it's not always present in OSM data\n",
        "        if 'operator' not in df.columns:\n",
        "            df['operator'] = np.nan\n",
        "\n",
        "        # 3. Fill missing values\n",
        "        df['name'] = df['name'].fillna('Unknown')\n",
        "        df['address'] = df['address'].fillna('Unknown')\n",
        "        df['operator'] = df['operator'].fillna('Unknown')\n",
        "\n",
        "        # NOTE: OSM data doesn't reliably contain 'capacity' or 'age_groups' tags.\n",
        "        # These columns will be created with placeholder values.\n",
        "\n",
        "        # 4. Add created_at and updated_at timestamps\n",
        "        df['created_at'] = pd.Timestamp.now()\n",
        "        df['updated_at'] = pd.Timestamp.now()\n",
        "\n",
        "        # 5. Select and rename columns to match the final schema\n",
        "        final_df = pd.DataFrame()\n",
        "        final_df['id'] = df['id']\n",
        "        final_df['name'] = df['name']\n",
        "        final_df['address'] = df['address']\n",
        "        final_df['district'] = df['city'].fillna('Unknown') # Using 'city' as a proxy for district\n",
        "        final_df['zip_code'] = df['postcode'].fillna('Unknown')\n",
        "        final_df['latitude'] = df['latitude']\n",
        "        final_df['longitude'] = df['longitude']\n",
        "        final_df['provider'] = df['operator'] # Mapping 'operator' to 'provider'\n",
        "        final_df['capacity'] = np.nan\n",
        "        final_df['age_groups'] = np.nan\n",
        "        final_df['created_at'] = df['created_at']\n",
        "        final_df['updated_at'] = df['updated_at']\n",
        "\n",
        "        # Save the cleaned DataFrame to a new CSV file\n",
        "        final_df.to_csv(cleaned_data_path, index=False)\n",
        "        print(f\"Cleaned data saved to {cleaned_data_path}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {raw_data_path} was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during data transformation: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define file paths\n",
        "    RAW_DATA_FILE = '../sources/kindergartens_berlin_raw_osm.csv'\n",
        "    CLEANED_DATA_FILE = '../data/kindergartens_berlin_cleaned.csv'\n",
        "\n",
        "    # Ensure the /data directory exists\n",
        "    os.makedirs(os.path.dirname(CLEANED_DATA_FILE), exist_ok=True)\n",
        "\n",
        "    # Run the cleaning function\n",
        "    clean_data(RAW_DATA_FILE, CLEANED_DATA_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhewYCo6g5u6",
        "outputId": "ae808719-291c-41b5-bbae-e5dde2cd8f9a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw data loaded successfully.\n",
            "Cleaned data saved to ../data/kindergartens_berlin_cleaned.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}