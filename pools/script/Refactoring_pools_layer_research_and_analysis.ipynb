{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939a5eec",
   "metadata": {},
   "source": [
    "# **ðŸŠ Pools Refactor â€” Enrichment Research and Analysis**\n",
    "\n",
    "## **Purpose**\n",
    "\n",
    "Create a repeatable, minimal pipeline to compare legacy pools with OpenStreetMap (OSM) so you can:\n",
    "\n",
    "1. Enrich existing legacy rows with missing details from OSM, and\n",
    "\n",
    "2. Add genuinely new, named public pools from OSM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8733862",
   "metadata": {},
   "source": [
    "## **Inputs & outputs**\n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "- pools.csv (legacy)\n",
    "\n",
    "- osm_pools_wide.csv (OSM wide export; optionally built in the notebook)\n",
    "\n",
    "**Outputs (CSV in project root)**:\n",
    "\n",
    "- legacy_enrichment_list.csv â€“ pairs of legacyâ†”OSM likely referring to the same place (for enrichment)\n",
    "\n",
    "- osm_new_public_named.csv â€“ OSM pools not in legacy, with a clear name (for addition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9b01c",
   "metadata": {},
   "source": [
    "## **Parameters (defaults in the notebook)**\n",
    "\n",
    "DIST_M = 100.0 â€” max distance (meters) to treat two points as the same place when names differ.\n",
    "\n",
    "STRICT_PUBLIC = False â€” lenient public filter for OSM (\"\"|yes|public|permissive and missing â†’ included).\n",
    "\n",
    "MAKE_OSM_WIDE â€” **set True only when you want to (re)build osm_pools_wide.csv via OSMnx.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626edb2",
   "metadata": {},
   "source": [
    "## **What the pipeline does (section-by-section)**\n",
    "\n",
    "### 1) Configure paths & parameters\n",
    "- Define file locations (`pools.csv`, `osm_pools_wide.csv`).\n",
    "- Set matching knobs:\n",
    "  - `DIST_M` â€” maximum distance (meters) to consider two entries the same place.\n",
    "  - `STRICT_PUBLIC` â€” OSM public-access strictness.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) (Optional) Build OSM wide export\n",
    "- Geocode the study area polygon with OSMnx.\n",
    "- Query & merge three OSM feature sets:\n",
    "  - `leisure=swimming_pool` (basins/complexes)\n",
    "  - `leisure=sports_centre` **filtered** to `sport=swimming`\n",
    "  - `leisure=swimming_area` (open-water/lidos)\n",
    "- Keep useful attributes (names, address, access, contacts, etc.).\n",
    "- Compute accurate centroids in a metric CRS (UTM33N) â†’ convert back to WGS84.\n",
    "- Write `osm_pools_wide.csv`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Helper functions (normalization, mapping)\n",
    "- Normalize names (accent fold, lowercase, remove punctuation).\n",
    "- **Coalesce OSM names** from multiple fields â†’ one best `name`:\n",
    "  - `name`, `official_name`, `short_name`, `alt_name`, `name:*`, `brand`, `operator`\n",
    "- Map Legacy and OSM to a **unified schema**; apply the public filter on OSM.\n",
    "\n",
    "---\n",
    "\n",
    "### 4) Load CSVs & map to unified schema\n",
    "- Read inputs and produce:\n",
    "  - `legacy_db` and `osm_db` with consistent columns and normalized names.\n",
    "\n",
    "---\n",
    "\n",
    "### 5) Build `legacy_enrichment_list` (candidates to enrich)\n",
    "- Create a light **blocking key**: first 10 chars of `name_norm`.\n",
    "- Join Legacy â†” OSM on the block to propose candidate pairs.\n",
    "- Compute Haversine distance (meters).\n",
    "- **Keep** a pair if:\n",
    "  - exact normalized name match **OR**\n",
    "  - distance â‰¤ `DIST_M`\n",
    "- Output includes `dist_m`, `name_match`, and OSM contact fields to drive enrichment.\n",
    "\n",
    "---\n",
    "\n",
    "### 6) Build `osm_new_public_named` (new & named)\n",
    "- From OSM public rows **not matched** above, keep only those with a **non-empty coalesced name**.\n",
    "- These are high-quality additions for your master list.\n",
    "\n",
    "---\n",
    "\n",
    "### 7) Save outputs + summary\n",
    "- Write two CSVs to the project root:\n",
    "  - `legacy_enrichment_list.csv`\n",
    "  - `osm_new_public_named.csv`\n",
    "- Print a compact run summary (counts + settings).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd60c4",
   "metadata": {},
   "source": [
    "-----\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645dc53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1680b255",
   "metadata": {},
   "source": [
    "\n",
    "# 1) Configure paths & parameters\n",
    "\n",
    "**What this does (bullet points):**\n",
    "- Sets your input file paths.\n",
    "- Lets you optionally build a fresh OSM export (set `MAKE_OSM_WIDE=True`).\n",
    "- Defines matching knobs:\n",
    "  - `DIST_M`: maximum distance (in meters) to consider two pools the same place.\n",
    "  - `STRICT_PUBLIC`: if `True`, keep only OSM rows with `access` exactly `yes|public`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9148ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured:\n",
      "  LEGACY_CSV = pools.csv\n",
      "  OSM_CSV    = osm_pools_wide.csv\n",
      "  MAKE_OSM_WIDE: True | PLACE: Berlin, Germany\n",
      "  DIST_M     = 100.0 m\n",
      "  STRICT_PUBLIC = False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def resolve_path(p):\n",
    "    return Path(str(p)).expanduser()\n",
    "\n",
    "# Inputs\n",
    "LEGACY_CSV = resolve_path(\"pools.csv\")            # legacy CSV\n",
    "OSM_CSV    = resolve_path(\"osm_pools_wide.csv\")   # will be created if MAKE_OSM_WIDE is True\n",
    "\n",
    "# Optional OSM build\n",
    "MAKE_OSM_WIDE = True              # set True to build OSM_CSV from OSMnx\n",
    "OSM_PLACE     = \"Berlin, Germany\"  # used if MAKE_OSM_WIDE=True\n",
    "\n",
    "# Parameters\n",
    "DIST_M = 100.0\n",
    "STRICT_PUBLIC = False\n",
    "\n",
    "print(\"Configured:\")\n",
    "print(\"  LEGACY_CSV =\", LEGACY_CSV)\n",
    "print(\"  OSM_CSV    =\", OSM_CSV)\n",
    "print(\"  MAKE_OSM_WIDE:\", MAKE_OSM_WIDE, \"| PLACE:\", OSM_PLACE)\n",
    "print(\"  DIST_M     =\", DIST_M, \"m\")\n",
    "print(\"  STRICT_PUBLIC =\", STRICT_PUBLIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf85808",
   "metadata": {},
   "source": [
    "\n",
    "# 2)Build OSM wide export\n",
    "\n",
    "**What this does (bullet points):**\n",
    "- Geocodes the study area polygon with OSMnx.\n",
    "- Queries three feature sets and merges them:\n",
    "  1. `leisure=swimming_pool` (actual basins / complexes)\n",
    "  2. `leisure=sports_centre` filtered to `sport=swimming`\n",
    "  3. `leisure=swimming_area` (open-water / lidos; include if useful)\n",
    "- Keeps useful attributes (names, address, access, contact, dimensions).\n",
    "- Computes accurate centroids in a **metric CRS (UTM33N)** and converts back to WGS84.\n",
    "- Writes a **wide** CSV (`osm_pools_wide.csv`) for downstream steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef60c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSMnx version: 2.0.6\n",
      "Counts â€” pools:919  sports_centres(swimming):65  swimming_areas:33  merged:1017\n",
      "[ok] Wrote OSM wide export â†’ osm_pools_wide.csv (rows=1017)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if MAKE_OSM_WIDE:\n",
    "    import osmnx as ox, geopandas as gpd, pandas as pd, numpy as np\n",
    "\n",
    "    print(\"OSMnx version:\", ox.__version__)\n",
    "    ox.settings.use_cache = True\n",
    "    ox.settings.log_console = False\n",
    "\n",
    "    # Place polygon\n",
    "    place_gdf = ox.geocode_to_gdf(OSM_PLACE)\n",
    "    if place_gdf.empty:\n",
    "        raise ValueError(f\"Could not geocode place: {OSM_PLACE}\")\n",
    "    place_poly = place_gdf.geometry.iloc[0]\n",
    "\n",
    "    # v1/v2 helper\n",
    "    def fetch(poly, tags):\n",
    "        if hasattr(ox, \"features_from_polygon\"):\n",
    "            return ox.features_from_polygon(poly, tags=tags)      # OSMnx 2.x\n",
    "        elif hasattr(ox, \"geometries_from_polygon\"):\n",
    "            return ox.geometries_from_polygon(poly, tags)         # OSMnx 1.x\n",
    "        else:\n",
    "            raise RuntimeError(\"OSMnx lacks expected geometry functions.\")\n",
    "\n",
    "    # Queries\n",
    "    g_pool = fetch(place_poly, {\"leisure\": \"swimming_pool\"})\n",
    "    g_sc   = fetch(place_poly, {\"leisure\": \"sports_centre\"})\n",
    "    g_area = fetch(place_poly, {\"leisure\": \"swimming_area\"})\n",
    "\n",
    "    def has_swimming(val):\n",
    "        if val is None or (isinstance(val, float) and np.isnan(val)): return False\n",
    "        if isinstance(val, (list, tuple, set)): return any(str(x).lower()==\"swimming\" for x in val)\n",
    "        return \"swimming\" in str(val).lower()\n",
    "\n",
    "    if \"sport\" in g_sc.columns:\n",
    "        g_sc = g_sc[g_sc[\"sport\"].apply(has_swimming)].copy()\n",
    "    else:\n",
    "        g_sc = g_sc.iloc[0:0].copy()\n",
    "\n",
    "    g = pd.concat([g_pool, g_sc, g_area], ignore_index=True, sort=False)\n",
    "    if g.empty:\n",
    "        raise ValueError(\"No pool-related features found for this area.\")\n",
    "\n",
    "    # Keep columns\n",
    "    prefer_cols = [\n",
    "        \"element_id\",\"osmid\",\"name\",\"official_name\",\"short_name\",\"alt_name\",\n",
    "        \"name:de\",\"name:en\",\"brand\",\"operator\",\n",
    "        \"access\",\n",
    "        \"addr:street\",\"addr:housenumber\",\"addr:postcode\",\"addr:city\",\n",
    "        \"website\",\"contact:website\",\"url\",\n",
    "        \"phone\",\"contact:phone\",\n",
    "        \"opening_hours\",\"wheelchair\",\n",
    "        \"length\",\"depth\",\"width\",\n",
    "        \"indoor\",\"covered\",\n",
    "        \"leisure\",\"sport\",\"swimming_pool\",\n",
    "        \"geometry\",\n",
    "    ]\n",
    "    have_cols = [c for c in prefer_cols if c in g.columns]\n",
    "    g = g[have_cols].copy()\n",
    "\n",
    "    # Centroids in metric CRS â†’ back to WGS84\n",
    "    if not isinstance(g, gpd.GeoDataFrame):\n",
    "        g = gpd.GeoDataFrame(g, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    g = g.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "    g_proj = g.to_crs(\"EPSG:32633\")  # UTM 33N ~ Berlin\n",
    "    cent   = g_proj.geometry.centroid\n",
    "    cent_w = cent.to_crs(\"EPSG:4326\")\n",
    "    g[\"lat\"] = cent_w.y\n",
    "    g[\"lon\"] = cent_w.x\n",
    "\n",
    "    # Flatten website/phone\n",
    "    def coalesce(df, *cols):\n",
    "        for c in cols:\n",
    "            if c in df.columns: return df[c]\n",
    "        return pd.Series(index=df.index, dtype=object)\n",
    "    g[\"website_flat\"] = coalesce(g, \"website\",\"contact:website\",\"url\")\n",
    "    g[\"phone_flat\"]   = coalesce(g, \"phone\",\"contact:phone\")\n",
    "\n",
    "    # Stable ID: element_id -> osmid -> surrogate\n",
    "    if \"element_id\" in g.columns and g[\"element_id\"].notna().any():\n",
    "        id_series = g[\"element_id\"].astype(\"string\")\n",
    "    elif \"osmid\" in g.columns and g[\"osmid\"].notna().any():\n",
    "        id_series = g[\"osmid\"].astype(\"string\")\n",
    "    else:\n",
    "        id_series = pd.Series(\"\", index=g.index, dtype=\"string\")\n",
    "    needs_sur = id_series.isna() | id_series.str.strip().eq(\"\") | (id_series == \"<NA>\")\n",
    "    id_series = id_series.astype(\"string\")\n",
    "    sur_idx = pd.Series(g.index.astype(str), index=g.index)\n",
    "    id_series.loc[needs_sur] = \"sur_\" + sur_idx.loc[needs_sur]\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"osm_id\": id_series,\n",
    "        \"name\": g.get(\"name\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"official_name\": g.get(\"official_name\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"short_name\": g.get(\"short_name\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"alt_name\": g.get(\"alt_name\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"name:de\": g.get(\"name:de\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"name:en\": g.get(\"name:en\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"brand\": g.get(\"brand\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"operator\": g.get(\"operator\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"access\": g.get(\"access\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"lat\": g[\"lat\"], \"lon\": g[\"lon\"],\n",
    "        \"addr_street\": g.get(\"addr:street\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"addr_housenumber\": g.get(\"addr:housenumber\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"addr_postcode\": g.get(\"addr:postcode\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"addr_city\": g.get(\"addr:city\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"website\": g[\"website_flat\"],\n",
    "        \"phone\": g[\"phone_flat\"],\n",
    "        \"opening_hours\": g.get(\"opening_hours\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"wheelchair\": g.get(\"wheelchair\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"length\": g.get(\"length\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"depth\": g.get(\"depth\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"width\": g.get(\"width\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"indoor\": g.get(\"indoor\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"covered\": g.get(\"covered\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"leisure\": g.get(\"leisure\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"sport\": g.get(\"sport\", pd.Series(index=g.index, dtype=object)),\n",
    "        \"swimming_pool\": g.get(\"swimming_pool\", pd.Series(index=g.index, dtype=object)),\n",
    "    }).drop_duplicates(subset=[\"osm_id\"], keep=\"first\")\n",
    "\n",
    "    print(f\"Counts â€” pools:{len(g_pool)}  sports_centres(swimming):{len(g_sc)}  swimming_areas:{len(g_area)}  merged:{len(out)}\")\n",
    "    out.to_csv(OSM_CSV, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[ok] Wrote OSM wide export â†’ {OSM_CSV} (rows={len(out)})\")\n",
    "else:\n",
    "    print(\"[skip] MAKE_OSM_WIDE is False â€” expecting OSM_CSV to already exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4870e149",
   "metadata": {},
   "source": [
    "\n",
    "# 3) Helper functions (normalization, mapping)\n",
    "\n",
    "**What this does (bullet points):**\n",
    "- Normalizes text and names for consistent matching.\n",
    "- Maps **Legacy** and **OSM** columns into a **unified schema**.\n",
    "- For OSM, coalesces the best available name from:  \n",
    "  `name`, `official_name`, `short_name`, `alt_name`, `name:*`, `brand`, `operator`.\n",
    "- Applies public-access filtering (`STRICT_PUBLIC`) for OSM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2383e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, math, unicodedata, re\n",
    "\n",
    "def normalize_ascii(s: str) -> str:\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    return \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "\n",
    "def normalize_name(s: str) -> str:\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = normalize_ascii(s).lower().strip()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def is_public_access(v, strict: bool=False) -> bool:\n",
    "    if v is None or (isinstance(v, float) and math.isnan(v)): return not strict\n",
    "    v = str(v).strip().lower()\n",
    "    if v in {\"private\",\"customers\",\"residents\"}: return False\n",
    "    return (v in {\"yes\",\"public\"} if strict else v in {\"\",\"yes\",\"public\",\"permissive\"} or v is None)\n",
    "\n",
    "def haversine_m(lat1, lon1, lat2, lon2) -> float:\n",
    "    if any(pd.isna([lat1, lon1, lat2, lon2])): return np.nan\n",
    "    R=6371000.0; phi1=math.radians(lat1); phi2=math.radians(lat2)\n",
    "    dphi=math.radians(lat2-lat1); dl=math.radians(lon2-lon1)\n",
    "    a=math.sin(dphi/2)**2+math.cos(phi1)*math.cos(phi2)*math.sin(dl/2)**2\n",
    "    return 2*R*math.asin(math.sqrt(a))\n",
    "\n",
    "def pick(df, *choices):\n",
    "    for c in choices:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "def map_osm_to_db(df: pd.DataFrame, strict_public: bool=False) -> pd.DataFrame:\n",
    "    if df.empty: return df.copy()\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    def cget(*choices):\n",
    "        for ch in choices:\n",
    "            if ch in cols: return cols[ch]\n",
    "        return None\n",
    "\n",
    "    # robust name coalescer\n",
    "    name_candidates = [\n",
    "        \"name\", \"official_name\", \"short_name\", \"alt_name\",\n",
    "        \"name:de\",\"name:en\",\"name:pl\",\"name:fr\",\"name:it\",\"name:es\",\n",
    "        \"brand\",\"operator\"\n",
    "    ]\n",
    "    present = [cols[c] for c in name_candidates if c in cols]\n",
    "    def coalesce_series(df, colnames):\n",
    "        if not colnames:\n",
    "            return pd.Series([\"\"]*len(df), index=df.index, dtype=object)\n",
    "        out = df[colnames[0]].astype(object).fillna(\"\")\n",
    "        for c in colnames[1:]:\n",
    "            nxt = df[c].astype(object).fillna(\"\")\n",
    "            use_next = out.astype(str).str.strip().eq(\"\")\n",
    "            out = out.where(~use_next, nxt)\n",
    "        return out.fillna(\"\").astype(str)\n",
    "    name_best = coalesce_series(df, present)\n",
    "\n",
    "    access_col=cget(\"access\"); lat_col=cget(\"lat\",\"latitude\"); lon_col=cget(\"lon\",\"longitude\")\n",
    "    dist_col=cget(\"district\",\"bezirk\",\"district_id\")\n",
    "    length_col=cget(\"length\",\"length_m\",\"pool_length\"); depth_col=cget(\"depth\",\"depth_m\",\"pool_depth\")\n",
    "    type_col=cget(\"pool_type\",\"leisure\",\"sport\",\"type\"); indoor_col=cget(\"indoor_outdoor\",\"indoor\",\"covered\")\n",
    "    phone_col=cget(\"phone\",\"contact:phone\"); web_col=cget(\"website\",\"contact:website\",\"url\")\n",
    "    oh_col=cget(\"opening_hours\"); wh_col=cget(\"wheelchair\")\n",
    "    id_col=cget(\"osm_id\",\"@id\",\"id\",\"element_id\",\"osmid\")\n",
    "\n",
    "    df_f = df.copy()\n",
    "    if access_col and access_col in df_f.columns:\n",
    "        df_f = df_f[df_f[access_col].apply(lambda v: is_public_access(v, strict_public))].copy()\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"source\":\"osm\",\n",
    "        \"source_id\": df_f.get(id_col, pd.Series(index=df_f.index, dtype=object)),\n",
    "        \"name\": name_best.reindex(df_f.index).fillna(\"\"),\n",
    "        \"name_norm\": name_best.reindex(df_f.index).fillna(\"\").astype(str).map(normalize_name),\n",
    "        \"lat\": pd.to_numeric(df_f.get(lat_col, np.nan), errors=\"coerce\"),\n",
    "        \"lon\": pd.to_numeric(df_f.get(lon_col, np.nan), errors=\"coerce\"),\n",
    "        \"address\": df_f.get(cget(\"addr:full\",\"address\",\"addr_street\"), \"\"),\n",
    "        \"district\": df_f.get(dist_col, \"\"),\n",
    "        \"pool_type\": df_f.get(type_col, \"\"),\n",
    "        \"indoor_outdoor\": df_f.get(indoor_col, \"\"),\n",
    "        \"length_m\": pd.to_numeric(df_f.get(length_col, np.nan), errors=\"coerce\"),\n",
    "        \"depth_m\": pd.to_numeric(df_f.get(depth_col, np.nan), errors=\"coerce\"),\n",
    "        \"phone\": df_f.get(phone_col, \"\"),\n",
    "        \"website\": df_f.get(web_col, \"\"),\n",
    "        \"opening_hours\": df_f.get(oh_col, \"\"),\n",
    "        \"wheelchair\": df_f.get(wh_col, \"\"),\n",
    "    })\n",
    "\n",
    "    # keep source of name for QA\n",
    "    def name_source_row(row):\n",
    "        for c in present:\n",
    "            val = row.get(c, \"\")\n",
    "            if isinstance(val, str) and val.strip():\n",
    "                return c\n",
    "        return \"\"\n",
    "    out[\"name_source\"] = \"\"\n",
    "    if present:\n",
    "        out[\"name_source\"] = df_f[present].apply(name_source_row, axis=1)\n",
    "\n",
    "    return out\n",
    "\n",
    "def map_legacy_to_db(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty: return df.copy()\n",
    "    cols={c.lower():c for c in df.columns}\n",
    "    def cget(*choices):\n",
    "        for ch in choices:\n",
    "            if ch in cols: return cols[ch]\n",
    "        return None\n",
    "    return pd.DataFrame({\n",
    "        \"source\":\"legacy\",\n",
    "        \"source_id\": df.get(cget(\"legacy_id\",\"id\"), pd.Series(index=df.index, dtype=object)),\n",
    "        \"name\": df.get(cget(\"name\",\"pool_name\"), \"\"),\n",
    "        \"name_norm\": df.get(cget(\"name\",\"pool_name\"), \"\").astype(str).map(normalize_name),\n",
    "        \"lat\": pd.to_numeric(df.get(cget(\"lat\",\"latitude\"), np.nan), errors=\"coerce\"),\n",
    "        \"lon\": pd.to_numeric(df.get(cget(\"lon\",\"longitude\"), np.nan), errors=\"coerce\"),\n",
    "        \"address\": df.get(cget(\"address\",\"addr\"), \"\"),\n",
    "        \"district\": df.get(cget(\"district\",\"bezirk\"), \"\"),\n",
    "        \"pool_type\": df.get(cget(\"pool_type\",\"type\"), \"\"),\n",
    "        \"indoor_outdoor\": df.get(cget(\"indoor_outdoor\",\"indoor\"), \"\"),\n",
    "        \"length_m\": pd.to_numeric(df.get(cget(\"length_m\",\"length\"), np.nan), errors=\"coerce\"),\n",
    "        \"depth_m\": pd.to_numeric(df.get(cget(\"depth_m\",\"depth\"), np.nan), errors=\"coerce\"),\n",
    "        \"phone\": df.get(cget(\"phone\"), \"\"),\n",
    "        \"website\": df.get(cget(\"website\",\"url\"), \"\"),\n",
    "        \"opening_hours\": df.get(cget(\"opening_hours\",\"hours\"), \"\"),\n",
    "        \"wheelchair\": df.get(cget(\"wheelchair\"), \"\"),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b27ab",
   "metadata": {},
   "source": [
    "\n",
    "# 4) Load CSVs & map to unified schema\n",
    "\n",
    "**What this does (bullet points):**\n",
    "- Reads `pools.csv` and `osm_pools_wide.csv`.\n",
    "- Maps both to the unified schema (`legacy_db`, `osm_db`).\n",
    "- Prints counts and a quick audit of how many OSM rows have a usable (coalesced) name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77582d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows â€” legacy: 144 | OSM wide: 1017 | OSM public subset: 307\n",
      "Non-empty names (coalesced): 69\n",
      "\n",
      "Top name sources:\n",
      "name_source\n",
      "        238\n",
      "name     69\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "legacy_raw = pd.read_csv(LEGACY_CSV)\n",
    "osm_raw    = pd.read_csv(OSM_CSV)\n",
    "\n",
    "legacy_db = map_legacy_to_db(legacy_raw)\n",
    "osm_db    = map_osm_to_db(osm_raw, strict_public=STRICT_PUBLIC)\n",
    "\n",
    "print(\"Rows â€” legacy:\", len(legacy_db),\n",
    "      \"| OSM wide:\", len(osm_raw),\n",
    "      \"| OSM public subset:\", len(osm_db))\n",
    "\n",
    "print(\"Non-empty names (coalesced):\", (osm_db['name'].astype(str).str.strip() != \"\").sum())\n",
    "if \"name_source\" in osm_db.columns:\n",
    "    print(\"\\nTop name sources:\")\n",
    "    print(osm_db['name_source'].value_counts(dropna=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f60fe2",
   "metadata": {},
   "source": [
    "\n",
    "# 5) Build legacy_enrichment_list (candidates to enrich)\n",
    "\n",
    "**What this does (bullet points):**\n",
    "- Creates lightweight **blocking keys** from normalized names (first 10 chars).\n",
    "- Joins Legacy â†” OSM on that block to get candidate pairs.\n",
    "- Flags **exact name matches** (`name_match`) and computes **distance** (meters).\n",
    "- Keeps candidates where **exact name matches** OR **distance â‰¤ `DIST_M`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d31a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legacy_enrichment_list: 47\n"
     ]
    }
   ],
   "source": [
    "\n",
    "L = legacy_db.assign(bucket=legacy_db[\"name_norm\"].str[:10])\n",
    "O = osm_db.assign(bucket=osm_db[\"name_norm\"].str[:10])\n",
    "\n",
    "cand = L.merge(O, on=\"bucket\", suffixes=(\"_l\",\"_o\"))\n",
    "cand[\"name_match\"] = (cand[\"name_norm_l\"].ne(\"\")) & cand[\"name_norm_l\"].eq(cand[\"name_norm_o\"])\n",
    "cand[\"dist_m\"] = cand.apply(lambda r: haversine_m(r[\"lat_l\"], r[\"lon_l\"], r[\"lat_o\"], r[\"lon_o\"]), axis=1)\n",
    "\n",
    "legacy_enrichment_list = cand[(cand[\"name_match\"]) | (cand[\"dist_m\"] <= DIST_M)].copy()\n",
    "\n",
    "keep_cols = [\n",
    "    \"source_id_l\",\"name_l\",\"lat_l\",\"lon_l\",\"address_l\",\"district_l\",\n",
    "    \"source_id_o\",\"name_o\",\"lat_o\",\"lon_o\",\"address_o\",\"district_o\",\n",
    "    \"dist_m\",\"name_match\",\"website_o\",\"opening_hours_o\",\"wheelchair_o\"\n",
    "]\n",
    "legacy_enrichment_list = legacy_enrichment_list[[c for c in keep_cols if c in legacy_enrichment_list.columns]]\n",
    "print(\"legacy_enrichment_list:\", len(legacy_enrichment_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63dd67",
   "metadata": {},
   "source": [
    "\n",
    "# 6) Build osm_new_public_named (OSM not in legacy, named only)\n",
    "\n",
    "**What this does (bullet points):**\n",
    "- Takes OSM **public** rows **not matched** to legacy above.\n",
    "- Requires a **non-empty coalesced name** for clear additions.\n",
    "- Final result is the list of **new named** pools from OSM to add.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78376e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osm_new_public_named: 24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matched_osm_ids = set(legacy_enrichment_list.get(\"source_id_o\", pd.Series(dtype=object)).dropna().tolist())\n",
    "osm_unmatched = osm_db[~osm_db[\"source_id\"].isin(matched_osm_ids)].copy()\n",
    "\n",
    "# coalesced name already resides in 'name'\n",
    "osm_new_public_named = osm_unmatched[osm_unmatched[\"name\"].astype(str).str.strip().ne(\"\")].copy()\n",
    "print(\"osm_new_public_named:\", len(osm_new_public_named))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f24d92",
   "metadata": {},
   "source": [
    "\n",
    "# 7) Save outputs + Summary\n",
    "\n",
    "**What this does (bullet points):**\n",
    "- Writes **CSV only** to the **main folder** (no Excel, no subfolders):\n",
    "  - `legacy_enrichment_list.csv`\n",
    "  - `osm_new_public_named.csv`\n",
    "- Prints a compact summary of key counts and settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6b9fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legacy_rows': 144, 'osm_public_rows': 307, 'legacy_enrichment_list': 47, 'osm_new_public_named': 24, 'dist_m': 100.0, 'strict_public': False, 'outputs': ['legacy_enrichment_list.csv', 'osm_new_public_named.csv']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write CSVs to project root\n",
    "legacy_enrichment_list.to_csv(Path(\"legacy_enrichment_list.csv\"), index=False)\n",
    "osm_new_public_named.to_csv(Path(\"osm_new_public_named.csv\"), index=False)\n",
    "\n",
    "summary = {\n",
    "    \"legacy_rows\": len(legacy_db),\n",
    "    \"osm_public_rows\": len(osm_db),\n",
    "    \"legacy_enrichment_list\": len(legacy_enrichment_list),\n",
    "    \"osm_new_public_named\": len(osm_new_public_named),\n",
    "    \"dist_m\": DIST_M,\n",
    "    \"strict_public\": STRICT_PUBLIC,\n",
    "    \"outputs\": [\"legacy_enrichment_list.csv\", \"osm_new_public_named.csv\"]\n",
    "}\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf15615",
   "metadata": {},
   "source": [
    "- Legacy rows: 144\n",
    "\n",
    "- OSM public subset: 307\n",
    "\n",
    "- Enrichment candidates (legacy_enrichment_list): 47\n",
    "\n",
    "- New OSM (named) to add (osm_new_public_named): 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a6ef3",
   "metadata": {},
   "source": [
    "# ==== Attribute coverage & gaps report (Legacy vs OSM) ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "254ba59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns only in OSM: ['name_source']\n",
      "Columns only in Legacy: []\n",
      "Columns in both (common): ['address', 'depth_m', 'district', 'indoor_outdoor', 'lat', 'length_m', 'lon', 'name', 'name_norm', 'opening_hours', 'phone', 'pool_type', 'source', 'source_id', 'website', 'wheelchair']\n",
      "\n",
      "=== Coverage Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legacy</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>osm_public_subset</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              source  rows\n",
       "0             legacy   144\n",
       "1  osm_public_subset   307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Completeness Comparison (common columns) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>legacy_filled_ratio</th>\n",
       "      <th>osm_filled_ratio</th>\n",
       "      <th>gap_osm_minus_legacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source_id</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>address</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>website</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>opening_hours</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indoor_outdoor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>depth_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>district</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>source</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pool_type</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>name</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>name_norm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  legacy_filled_ratio  osm_filled_ratio  \\\n",
       "0        source_id                  0.0             1.000   \n",
       "1       wheelchair                  0.0             0.143   \n",
       "2          address                  0.0             0.137   \n",
       "3          website                  0.0             0.091   \n",
       "4    opening_hours                  0.0             0.078   \n",
       "5            phone                  0.0             0.042   \n",
       "6   indoor_outdoor                  0.0             0.029   \n",
       "7         length_m                  0.0             0.010   \n",
       "8          depth_m                  0.0             0.000   \n",
       "9              lon                  1.0             1.000   \n",
       "10             lat                  1.0             1.000   \n",
       "11        district                  0.0             0.000   \n",
       "12          source                  1.0             1.000   \n",
       "13       pool_type                  1.0             1.000   \n",
       "14            name                  1.0             0.225   \n",
       "15       name_norm                  1.0             0.225   \n",
       "\n",
       "    gap_osm_minus_legacy  \n",
       "0                  1.000  \n",
       "1                  0.143  \n",
       "2                  0.137  \n",
       "3                  0.091  \n",
       "4                  0.078  \n",
       "5                  0.042  \n",
       "6                  0.029  \n",
       "7                  0.010  \n",
       "8                  0.000  \n",
       "9                  0.000  \n",
       "10                 0.000  \n",
       "11                 0.000  \n",
       "12                 0.000  \n",
       "13                 0.000  \n",
       "14                -0.775  \n",
       "15                -0.775  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Spec Fields Gap (pool_type, length_m, depth_m) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>legacy_filled_ratio</th>\n",
       "      <th>osm_filled_ratio</th>\n",
       "      <th>gap_osm_minus_legacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depth_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>length_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pool_type</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      column  legacy_filled_ratio  osm_filled_ratio  gap_osm_minus_legacy\n",
       "0    depth_m                  0.0              0.00                  0.00\n",
       "1   length_m                  0.0              0.01                  0.01\n",
       "2  pool_type                  1.0              1.00                  0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 columns where OSM is more complete than Legacy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>legacy_filled_ratio</th>\n",
       "      <th>osm_filled_ratio</th>\n",
       "      <th>gap_osm_minus_legacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source_id</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>address</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>website</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>opening_hours</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indoor_outdoor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>length_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>depth_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  legacy_filled_ratio  osm_filled_ratio  gap_osm_minus_legacy\n",
       "0       source_id                  0.0             1.000                 1.000\n",
       "1      wheelchair                  0.0             0.143                 0.143\n",
       "2         address                  0.0             0.137                 0.137\n",
       "3         website                  0.0             0.091                 0.091\n",
       "4   opening_hours                  0.0             0.078                 0.078\n",
       "5           phone                  0.0             0.042                 0.042\n",
       "6  indoor_outdoor                  0.0             0.029                 0.029\n",
       "7        length_m                  0.0             0.010                 0.010\n",
       "8         depth_m                  0.0             0.000                 0.000\n",
       "9             lon                  1.0             1.000                 0.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 columns where Legacy is more complete than OSM:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>legacy_filled_ratio</th>\n",
       "      <th>osm_filled_ratio</th>\n",
       "      <th>gap_osm_minus_legacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name_norm</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225</td>\n",
       "      <td>-0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depth_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>source</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pool_type</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>district</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>length_m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>indoor_outdoor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  legacy_filled_ratio  osm_filled_ratio  gap_osm_minus_legacy\n",
       "0            name                  1.0             0.225                -0.775\n",
       "1       name_norm                  1.0             0.225                -0.775\n",
       "2             lat                  1.0             1.000                 0.000\n",
       "3         depth_m                  0.0             0.000                 0.000\n",
       "4             lon                  1.0             1.000                 0.000\n",
       "5          source                  1.0             1.000                 0.000\n",
       "6       pool_type                  1.0             1.000                 0.000\n",
       "7        district                  0.0             0.000                 0.000\n",
       "8        length_m                  0.0             0.010                 0.010\n",
       "9  indoor_outdoor                  0.0             0.029                 0.029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Acceptance-Criteria View ===\n",
      "- Coverage: legacy=144 | osm_public_subset=307\n",
      "- Attributes compared: in-memory (no files written)\n",
      "- Gaps (spec fields): see table above for pool_type/length_m/depth_m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 0) Pretty display options (optional)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "\n",
    "# 1) Which columns exist only in OSM vs only in Legacy?\n",
    "legacy_cols = set(legacy_db.columns)\n",
    "osm_cols    = set(osm_db.columns)\n",
    "\n",
    "only_in_osm    = sorted(osm_cols - legacy_cols)\n",
    "only_in_legacy = sorted(legacy_cols - osm_cols)\n",
    "common_cols    = sorted(osm_cols & legacy_cols)\n",
    "\n",
    "print(\"Columns only in OSM:\", only_in_osm)\n",
    "print(\"Columns only in Legacy:\", only_in_legacy)\n",
    "print(\"Columns in both (common):\", common_cols)\n",
    "\n",
    "# 2) Coverage (row counts) â€“ high-level\n",
    "coverage_summary = pd.DataFrame(\n",
    "    {\"source\": [\"legacy\", \"osm_public_subset\"], \"rows\": [len(legacy_db), len(osm_db)]}\n",
    ")\n",
    "print(\"\\n=== Coverage Summary ===\")\n",
    "display(coverage_summary)\n",
    "\n",
    "# 3) Completeness by column (share of filled values) for common fields\n",
    "def column_filled_ratio(df: pd.DataFrame, col: str) -> float:\n",
    "    s = df[col]\n",
    "    # Numeric -> filled if non-null\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return float(s.notna().mean())\n",
    "    # Datetime/boolean -> filled if non-null\n",
    "    if pd.api.types.is_datetime64_any_dtype(s) or pd.api.types.is_bool_dtype(s):\n",
    "        return float(s.notna().mean())\n",
    "    # Everything else (object/string etc.) -> filled if non-null and non-empty after strip\n",
    "    s_str = s.astype(str)\n",
    "    return float((s.notna() & s_str.str.strip().ne(\"\")).mean())\n",
    "\n",
    "def completeness_for(df: pd.DataFrame, cols: list[str]) -> pd.Series:\n",
    "    if not cols:\n",
    "        return pd.Series(dtype=float)\n",
    "    return pd.Series({c: column_filled_ratio(df, c) for c in cols})\n",
    "\n",
    "legacy_comp = completeness_for(legacy_db, common_cols)\n",
    "osm_comp    = completeness_for(osm_db, common_cols)\n",
    "\n",
    "comp = pd.DataFrame({\n",
    "    \"column\": common_cols,\n",
    "    \"legacy_filled_ratio\": [legacy_comp.get(c, float(\"nan\")) for c in common_cols],\n",
    "    \"osm_filled_ratio\":    [osm_comp.get(c, float(\"nan\")) for c in common_cols],\n",
    "})\n",
    "comp[\"gap_osm_minus_legacy\"] = comp[\"osm_filled_ratio\"] - comp[\"legacy_filled_ratio\"]\n",
    "\n",
    "print(\"\\n=== Completeness Comparison (common columns) ===\")\n",
    "display(comp.sort_values(\"gap_osm_minus_legacy\", ascending=False).reset_index(drop=True))\n",
    "\n",
    "# 4) Focus on spec fields (pool type, length, depth) â€“ explicit gap check\n",
    "spec_cols = [c for c in [\"pool_type\", \"length_m\", \"depth_m\"] if c in common_cols]\n",
    "spec = comp[comp[\"column\"].isin(spec_cols)].sort_values(\"column\")\n",
    "\n",
    "print(\"\\n=== Spec Fields Gap (pool_type, length_m, depth_m) ===\")\n",
    "if not spec.empty:\n",
    "    display(spec.reset_index(drop=True))\n",
    "else:\n",
    "    print(\"None of the spec fields were found in the common schema.\")\n",
    "\n",
    "# 5) Quick peek of where OSM vs Legacy adds more value\n",
    "print(\"\\nTop 10 columns where OSM is more complete than Legacy:\")\n",
    "display(comp.sort_values(\"gap_osm_minus_legacy\", ascending=False).head(10).reset_index(drop=True))\n",
    "\n",
    "print(\"\\nTop 10 columns where Legacy is more complete than OSM:\")\n",
    "display(comp.sort_values(\"gap_osm_minus_legacy\", ascending=True).head(10).reset_index(drop=True))\n",
    "\n",
    "# 6) Acceptance-Criteria view (printed summary)\n",
    "print(\"\\n=== Acceptance-Criteria View ===\")\n",
    "print(f\"- Coverage: legacy={len(legacy_db)} | osm_public_subset={len(osm_db)}\")\n",
    "print(\"- Attributes compared: in-memory (no files written)\")\n",
    "if not spec.empty:\n",
    "    print(\"- Gaps (spec fields): see table above for pool_type/length_m/depth_m\")\n",
    "else:\n",
    "    print(\"- Gaps (spec fields): none detected in common columns\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ce433",
   "metadata": {},
   "source": [
    "1. Coverage: legacy 144 vs OSM (public subset) 307 â†’ OSM sees more venues overall.\n",
    "\n",
    "2. Schema overlap: everything is shared except name_source (OSM-only helper column).\n",
    "\n",
    "3. Where OSM wins (more complete):\n",
    "source_id, wheelchair, address, website, opening_hours, phone, some indoor_outdoor.\n",
    "(Exactly what we want OSM for: contact & accessibility.)\n",
    "\n",
    "4. Where legacy wins (more complete):\n",
    "name and name_norm (legacy 100% vs OSM ~22.5%).\n",
    "(OSM has many unnamed features even after coalescing.)\n",
    "\n",
    "5. Spec fields ( â€œgapsâ€):\n",
    "pool_type is full in both; length_m and depth_m are basically empty on both sides (â‰ˆ0â€“1%) - therefore lenght and depth can be not pulled at all from OSM \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa3f6b",
   "metadata": {},
   "source": [
    "**OSM does not fully replace the old source today (naming too sparse, specs missing).**\n",
    "\n",
    "**Best choice: hybrid enrichment â€” legacy for the backbone; OSM to fill contact, hours, accessibility, and some addresses.**\n",
    "\n",
    "**Keep specs separate until we secure a reliable source for length/depth.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
