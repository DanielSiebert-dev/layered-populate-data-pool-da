{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a51fdb",
   "metadata": {},
   "source": [
    "## Cleaning \n",
    "    * Cleans data from berlin_venues_raw created by the venues_craper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19973b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a784169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded variable 'df' from URI\n",
    "\n",
    "df = pd.read_csv(r'/Users/giovanigoltara/Documents/webeet/layered-populate-data-pool-da/venues/sources/berlin_venues_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3cde20",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['district']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nc/rtwbjn4545v3r4g5t0kbb1hh0000gn/T/ipykernel_5933/1127895301.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop rows with missing data in columns: 'name', 'district'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'district'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Drop duplicate rows across all columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6673\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6674\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6675\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6677\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6678\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['district']"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing data in columns: 'name', 'district'\n",
    "df = df.dropna(subset=['name', 'district'])\n",
    "\n",
    "# Drop duplicate rows across all columns\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338eb5b",
   "metadata": {},
   "source": [
    "## Opening hours library\n",
    "    * This code creates a normalized library of opening hours for each venue when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Hours parser code\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "DAY_ORDER = [\"Mo\", \"Tu\", \"We\", \"Th\", \"Fr\", \"Sa\", \"Su\"]\n",
    "\n",
    "def _normalize_day_text(s: str) -> str:\n",
    "    t = (s or \"\").strip()\n",
    "    t = t.replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"−\", \"-\").replace(\" to \", \"-\")\n",
    "    low = t.lower()\n",
    "    repl = [\n",
    "        (r'\\bpublic\\s*holidays?\\b', 'PH'), (r'\\bph\\b', 'PH'),\n",
    "        (r'\\bmonday\\b', 'Mo'), (r'\\bmon\\b', 'Mo'), (r'\\bmo\\b', 'Mo'),\n",
    "        (r'\\btuesday\\b', 'Tu'), (r'\\btues\\b', 'Tu'), (r'\\btue\\b', 'Tu'), (r'\\btu\\b', 'Tu'),\n",
    "        (r'\\bwednesday\\b', 'We'), (r'\\bweds\\b', 'We'), (r'\\bwed\\b', 'We'), (r'\\bwe\\b', 'We'),\n",
    "        (r'\\bthursday\\b', 'Th'), (r'\\bthurs\\b', 'Th'), (r'\\bthur\\b', 'Th'), (r'\\bthu\\b', 'Th'),\n",
    "        (r'\\bfriday\\b', 'Fr'), (r'\\bfri\\b', 'Fr'), (r'\\bfr\\b', 'Fr'),\n",
    "        (r'\\bsaturday\\b', 'Sa'), (r'\\bsat\\b', 'Sa'), (r'\\bsa\\b', 'Sa'),\n",
    "        (r'\\bsunday\\b', 'Su'), (r'\\bsun\\b', 'Su'), (r'\\bsu\\b', 'Su'),\n",
    "    ]\n",
    "    for pat, rep in repl:\n",
    "        low = re.sub(pat, rep, low)\n",
    "    return re.sub(r'\\s+', ' ', low).strip()\n",
    "\n",
    "def _expand_days_token(tok: str):\n",
    "    tok = tok.strip()\n",
    "    if not tok: return []\n",
    "    if tok == \"PH\": return [\"PH\"]\n",
    "    if \"-\" in tok:\n",
    "        a, b = [x.strip() for x in tok.split(\"-\", 1)]\n",
    "        if a in DAY_ORDER and b in DAY_ORDER:\n",
    "            ai, bi = DAY_ORDER.index(a), DAY_ORDER.index(b)\n",
    "            return DAY_ORDER[ai:bi+1] if ai <= bi else DAY_ORDER[ai:] + DAY_ORDER[:bi+1]\n",
    "        return []\n",
    "    return [tok] if tok in DAY_ORDER else []\n",
    "\n",
    "def _parse_time_value(t: str) -> str:\n",
    "    t = t.strip()\n",
    "    if t.lower() in {\"midnight\", \"24\", \"24:00\"}: return \"00:00\"\n",
    "    if t.lower() in {\"noon\", \"12pm\"}: return \"12:00\"\n",
    "    if re.match(r'^\\d{1,2}:\\d{1,2}$', t):\n",
    "        h, m = t.split(\":\"); return f\"{int(h):02d}:{int(m):02d}\"\n",
    "    if re.match(r'^\\d{1,2}$', t):\n",
    "        return f\"{int(t):02d}:00\"\n",
    "    return t\n",
    "\n",
    "def _parse_segment(seg: str):\n",
    "    seg = _normalize_day_text(seg)\n",
    "    mdig = re.search(r'\\d', seg)\n",
    "    day_part = seg[:mdig.start()].strip().rstrip(\",\") if mdig else seg\n",
    "    times_part = seg[mdig.start():].strip() if mdig else \"\"\n",
    "    if day_part:\n",
    "        day_tokens = [p.strip() for p in day_part.split(\",\") if p.strip()]\n",
    "        days = []\n",
    "        for tok in day_tokens:\n",
    "            days += _expand_days_token(tok)\n",
    "    else:\n",
    "        days = DAY_ORDER[:]\n",
    "    times = []\n",
    "    if times_part:\n",
    "        for tseg in [x.strip() for x in re.split(r',|\\s*/\\s*', times_part) if x.strip()]:\n",
    "            if tseg.endswith(\"+\"):\n",
    "                times.append([_parse_time_value(tseg[:-1]), \"late\"])\n",
    "            elif \"-\" in tseg:\n",
    "                a, b = tseg.split(\"-\", 1)\n",
    "                times.append([_parse_time_value(a), _parse_time_value(b)])\n",
    "            else:\n",
    "                tok = tseg.lower()\n",
    "                if tok in {\"closed\", \"off\"}:\n",
    "                    times.append([\"closed\", \"closed\"])\n",
    "                else:\n",
    "                    times.append([_parse_time_value(tseg), \"\"])\n",
    "    return days, times\n",
    "\n",
    "def opening_hours_to_dict(text: str):\n",
    "    if not isinstance(text, str) or text.strip() == \"\" or \"missing\" in text.lower():\n",
    "        return None\n",
    "    result = {}\n",
    "    segments = [s.strip() for s in re.split(r';|\\||·', text) if s.strip()]\n",
    "    if not segments: segments = [text.strip()]\n",
    "    for seg in segments:\n",
    "        days, times = _parse_segment(seg)\n",
    "        if not times: continue\n",
    "        for d in days:\n",
    "            result.setdefault(d, []).extend(times)\n",
    "    return result\n",
    "\n",
    "# --- APPLY transformation directly to df ---\n",
    "df[\"opening_hours_dict\"] = df[\"opening_hours\"].apply(opening_hours_to_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
